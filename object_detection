"""Object detection
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/object_detection.ipynb
##### Copyright 2018 The TensorFlow Hub Authors.
Licensed under the Apache License, Version 2.0 (the "License");
"""

# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

"""# Object Detection
## Setup
"""

#@title Imports and function definitions

# For running inference on the TF-Hub module.
import tensorflow as tf

import tensorflow_hub as hub

# For downloading the image.
# import matplotlib.pyplot as plt
# import tempfile
# from six.moves.urllib.request import urlopen
# from six import BytesIO

# For drawing onto the image.
import numpy as np
from PIL import Image
from PIL import ImageColor
from PIL import ImageDraw
from PIL import ImageFont
from PIL import ImageOps

# For measuring the inference time.
import time

# Print Tensorflow version
print(tf.__version__)

# Check available GPU devices.
print("The following GPU devices are available: %s" % tf.test.gpu_device_name())

"""## Example use
### Helper functions for downloading images and for visualization.
Visualization code adapted from [TF object detection API](https://github.com/tensorflow/models/blob/master/research/object_detection/utils/visualization_utils.py) for the simplest required functionality.
"""


## display our image
def display_image(image):
  fig = plt.figure(figsize=(20, 15))
  plt.grid(False)
  plt.imshow(image)

## insert image from file and download it to resize it
class ImageFactory:
  def create_image(self, url, new_width=256, new_height=256, display=False):
    _, filename = tempfile.mkstemp(suffix=".jpg")
    response = urlopen(url)
    image_data = response.read()
    image_data = BytesIO(image_data)
    pil_image = Image.open(image_data)
    pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)
    pil_image_rgb = pil_image.convert("RGB")
    pil_image_rgb.save(filename, format="JPEG", quality=90)
    print("Image downloaded to %s." % filename)
    if display:
      display_image(pil_image)
    return filename

# Create an instance of the ImageFactory class
image_factory = ImageFactory()

# Use the ImageFactory to create an image from a URL
downloaded_image_path = image_factory.create_image(image_url, display=True)



## bound a box on our image to get dimensions
def draw_bounding_box_on_image(image, color, font, thickness=4, display_str_list=(), 
                                top=0, left=0, bottom=1, right=1):
  """Adds a bounding box to an image."""
  im_width, im_height = image.size
  bounding_box_coordinates = calculate_bounding_box_coordinates(im_width, im_height, top, left, bottom, right)

  with ImageDraw.Draw(image) as draw:
    draw.line([bounding_box_coordinates, (left, bottom), (right, bottom), (right, top),
               (left, top)],
              width=thickness,
              fill=color)

def calculate_bounding_box_coordinates(im_width, im_height, top, left, bottom, right):
  return (left * im_width, top * im_height, bottom * im_height, right * im_width)
  
  
try:
    font = ImageFont.truetype("/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf",
                              25)
except IOError:
    print("Font not found, using default font.")
    font = ImageFont.load_default()

for i in range(min(boxes.shape[0], max_boxes)):
    if scores[i] >= min_score:
        top, left, bottom, right = tuple(boxes[i])
        display_str = "{}: {}%".format(class_names[i].decode("ascii"),
                                       int(100 * scores[i]))
        color = colors[hash(class_names[i]) % len(colors)]
        image_pil = Image.fromarray(np.uint8(image)).convert("RGB")
        draw_bounding_box_on_image(
            image_pil,
            color,
            font,
            display_str_list=[display_str],
            top=top,
            left=left,
            bottom=bottom,
            right=right
        )
        np.copyto(image, np.array(image_pil))
return image


"""## Apply module
Load a public image from Open Images v4, save locally, and display.
"""

# By Heiko Gorski, Source: https://commons.wikimedia.org/wiki/File:Naxos_Taverna.jpg
image_url = "https://upload.wikimedia.org/wikipedia/commons/6/60/Naxos_Taverna.jpg"  #@param
downloaded_image_path = download_and_resize_image(image_url, 1280, 856, True)
# camera_image_path = ""

"""Pick an object detection module and apply on the downloaded image. Modules:
* **FasterRCNN+InceptionResNet V2**: high accuracy,
* **ssd+mobilenet V2**: small and fast.
"""

module_handle = "https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1" #@param ["https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1", "https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1"]

detector = hub.load(module_handle).signatures['default']

class DetectorAdapter:
  def __init__(self, detector):
    self.detector = detector

  def run(self, path):
    img = load_img(path)

    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]
    start_time = time.time()
    result = self.detector(converted_img)
    end_time = time.time()

    result = {key:value.numpy() for key,value in result.items()}

    print("Found %d objects." % len(result["detection_scores"]))
    print("Inference time: ", end_time-start_time)

    image_with_boxes = draw_boxes(
        img.numpy(), result["detection_boxes"],
        result["detection_class_entities"], result["detection_scores"])

    display_image(image_with_boxes)

# Create an instance of the adapter class and pass the `detector` object to its constructor
detector_adapter = DetectorAdapter(detector)

# Use the adapter to run the object detection
detector_adapter.run(downloaded_image_path)
